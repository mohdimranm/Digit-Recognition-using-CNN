{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout,BatchNormalization\n",
    "from keras.preprocessing.image  import load_img,ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test= pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "X_train= train.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efc8504fac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count       784\n",
       " unique        1\n",
       " top       False\n",
       " freq        784\n",
       " dtype: object, count       784\n",
       " unique        1\n",
       " top       False\n",
       " freq        784\n",
       " dtype: object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe(), test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype('float32')/255\n",
    "test=test.astype('float32')/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efc852fd080>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=X_train.iloc[0].as_matrix()\n",
    "plt.imshow(img.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=keras.utils.to_categorical(y_train,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values.reshape(-1,28,28,1)\n",
    "test= test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid=train_test_split(X_train,y_train,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35700, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efc852d1128>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1][:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 110,586\n",
      "Trainable params: 110,106\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding= 'same',activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32,kernel_size=4,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64,kernel_size=4,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=250\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True,rotation_range=0.5,zoom_range=0.1)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      " - 10s - loss: 1.1806 - acc: 0.5837 - val_loss: 0.5910 - val_acc: 0.8024\n",
      "Epoch 2/250\n",
      " - 7s - loss: 0.5159 - acc: 0.8237 - val_loss: 0.4094 - val_acc: 0.8646\n",
      "Epoch 3/250\n",
      " - 7s - loss: 0.3719 - acc: 0.8786 - val_loss: 0.1912 - val_acc: 0.9390\n",
      "Epoch 4/250\n",
      " - 7s - loss: 0.2846 - acc: 0.9087 - val_loss: 0.1199 - val_acc: 0.9616\n",
      "Epoch 5/250\n",
      " - 7s - loss: 0.2411 - acc: 0.9222 - val_loss: 0.1404 - val_acc: 0.9551\n",
      "Epoch 6/250\n",
      " - 7s - loss: 0.2088 - acc: 0.9325 - val_loss: 0.0886 - val_acc: 0.9721\n",
      "Epoch 7/250\n",
      " - 7s - loss: 0.1871 - acc: 0.9400 - val_loss: 0.0953 - val_acc: 0.9697\n",
      "Epoch 8/250\n",
      " - 7s - loss: 0.1714 - acc: 0.9447 - val_loss: 0.0695 - val_acc: 0.9787\n",
      "Epoch 9/250\n",
      " - 7s - loss: 0.1633 - acc: 0.9479 - val_loss: 0.0780 - val_acc: 0.9762\n",
      "Epoch 10/250\n",
      " - 7s - loss: 0.1579 - acc: 0.9508 - val_loss: 0.0716 - val_acc: 0.9770\n",
      "Epoch 11/250\n",
      " - 7s - loss: 0.1488 - acc: 0.9528 - val_loss: 0.0679 - val_acc: 0.9792\n",
      "Epoch 12/250\n",
      " - 7s - loss: 0.1407 - acc: 0.9552 - val_loss: 0.0840 - val_acc: 0.9748\n",
      "Epoch 13/250\n",
      " - 7s - loss: 0.1375 - acc: 0.9566 - val_loss: 0.0580 - val_acc: 0.9825\n",
      "Epoch 14/250\n",
      " - 7s - loss: 0.1291 - acc: 0.9592 - val_loss: 0.0588 - val_acc: 0.9819\n",
      "Epoch 15/250\n",
      " - 7s - loss: 0.1280 - acc: 0.9593 - val_loss: 0.0613 - val_acc: 0.9810\n",
      "Epoch 16/250\n",
      " - 7s - loss: 0.1225 - acc: 0.9608 - val_loss: 0.0482 - val_acc: 0.9843\n",
      "Epoch 17/250\n",
      " - 7s - loss: 0.1208 - acc: 0.9618 - val_loss: 0.0580 - val_acc: 0.9821\n",
      "Epoch 18/250\n",
      " - 7s - loss: 0.1151 - acc: 0.9632 - val_loss: 0.0659 - val_acc: 0.9781\n",
      "Epoch 19/250\n",
      " - 7s - loss: 0.1145 - acc: 0.9631 - val_loss: 0.0508 - val_acc: 0.9848\n",
      "Epoch 20/250\n",
      " - 7s - loss: 0.1154 - acc: 0.9640 - val_loss: 0.0480 - val_acc: 0.9856\n",
      "Epoch 21/250\n",
      " - 7s - loss: 0.1104 - acc: 0.9662 - val_loss: 0.0398 - val_acc: 0.9878\n",
      "Epoch 22/250\n",
      " - 7s - loss: 0.1085 - acc: 0.9645 - val_loss: 0.0406 - val_acc: 0.9870\n",
      "Epoch 23/250\n",
      " - 7s - loss: 0.1019 - acc: 0.9670 - val_loss: 0.0609 - val_acc: 0.9805\n",
      "Epoch 24/250\n",
      " - 7s - loss: 0.1012 - acc: 0.9684 - val_loss: 0.0478 - val_acc: 0.9849\n",
      "Epoch 25/250\n",
      " - 7s - loss: 0.1062 - acc: 0.9671 - val_loss: 0.0510 - val_acc: 0.9851\n",
      "Epoch 26/250\n",
      " - 7s - loss: 0.1050 - acc: 0.9664 - val_loss: 0.0457 - val_acc: 0.9867\n",
      "Epoch 27/250\n",
      " - 7s - loss: 0.1015 - acc: 0.9690 - val_loss: 0.0387 - val_acc: 0.9870\n",
      "Epoch 28/250\n",
      " - 7s - loss: 0.1005 - acc: 0.9686 - val_loss: 0.0476 - val_acc: 0.9860\n",
      "Epoch 29/250\n",
      " - 7s - loss: 0.1012 - acc: 0.9688 - val_loss: 0.0442 - val_acc: 0.9865\n",
      "Epoch 30/250\n",
      " - 7s - loss: 0.0975 - acc: 0.9689 - val_loss: 0.0509 - val_acc: 0.9848\n",
      "Epoch 31/250\n",
      " - 7s - loss: 0.0970 - acc: 0.9699 - val_loss: 0.0452 - val_acc: 0.9862\n",
      "Epoch 32/250\n",
      " - 7s - loss: 0.0947 - acc: 0.9703 - val_loss: 0.0428 - val_acc: 0.9868\n",
      "Epoch 33/250\n",
      " - 7s - loss: 0.0953 - acc: 0.9706 - val_loss: 0.0361 - val_acc: 0.9886\n",
      "Epoch 34/250\n",
      " - 7s - loss: 0.0948 - acc: 0.9703 - val_loss: 0.0424 - val_acc: 0.9860\n",
      "Epoch 35/250\n",
      " - 7s - loss: 0.0933 - acc: 0.9702 - val_loss: 0.0370 - val_acc: 0.9884\n",
      "Epoch 36/250\n",
      " - 7s - loss: 0.0904 - acc: 0.9707 - val_loss: 0.0409 - val_acc: 0.9876\n",
      "Epoch 37/250\n",
      " - 7s - loss: 0.0902 - acc: 0.9724 - val_loss: 0.0514 - val_acc: 0.9838\n",
      "Epoch 38/250\n",
      " - 7s - loss: 0.0906 - acc: 0.9718 - val_loss: 0.0527 - val_acc: 0.9840\n",
      "Epoch 39/250\n",
      " - 7s - loss: 0.0866 - acc: 0.9722 - val_loss: 0.0393 - val_acc: 0.9862\n",
      "Epoch 40/250\n",
      " - 7s - loss: 0.0886 - acc: 0.9728 - val_loss: 0.0349 - val_acc: 0.9892\n",
      "Epoch 41/250\n",
      " - 7s - loss: 0.0886 - acc: 0.9707 - val_loss: 0.0439 - val_acc: 0.9868\n",
      "Epoch 42/250\n",
      " - 7s - loss: 0.0893 - acc: 0.9708 - val_loss: 0.0496 - val_acc: 0.9846\n",
      "Epoch 43/250\n",
      " - 7s - loss: 0.0892 - acc: 0.9713 - val_loss: 0.0393 - val_acc: 0.9875\n",
      "Epoch 44/250\n",
      " - 8s - loss: 0.0858 - acc: 0.9723 - val_loss: 0.0378 - val_acc: 0.9887\n",
      "Epoch 45/250\n",
      " - 7s - loss: 0.0889 - acc: 0.9715 - val_loss: 0.0472 - val_acc: 0.9865\n",
      "Epoch 46/250\n",
      " - 7s - loss: 0.0864 - acc: 0.9721 - val_loss: 0.0359 - val_acc: 0.9881\n",
      "Epoch 47/250\n",
      " - 7s - loss: 0.0843 - acc: 0.9731 - val_loss: 0.0476 - val_acc: 0.9862\n",
      "Epoch 48/250\n",
      " - 7s - loss: 0.0866 - acc: 0.9725 - val_loss: 0.0448 - val_acc: 0.9865\n",
      "Epoch 49/250\n",
      " - 7s - loss: 0.0829 - acc: 0.9735 - val_loss: 0.0379 - val_acc: 0.9879\n",
      "Epoch 50/250\n",
      " - 7s - loss: 0.0845 - acc: 0.9741 - val_loss: 0.0376 - val_acc: 0.9876\n",
      "Epoch 51/250\n",
      " - 7s - loss: 0.0817 - acc: 0.9739 - val_loss: 0.0440 - val_acc: 0.9862\n",
      "Epoch 52/250\n",
      " - 7s - loss: 0.0850 - acc: 0.9721 - val_loss: 0.0323 - val_acc: 0.9890\n",
      "Epoch 53/250\n",
      " - 7s - loss: 0.0826 - acc: 0.9742 - val_loss: 0.0408 - val_acc: 0.9873\n",
      "Epoch 54/250\n",
      " - 7s - loss: 0.0813 - acc: 0.9739 - val_loss: 0.0429 - val_acc: 0.9865\n",
      "Epoch 55/250\n",
      " - 7s - loss: 0.0822 - acc: 0.9738 - val_loss: 0.0337 - val_acc: 0.9889\n",
      "Epoch 56/250\n",
      " - 7s - loss: 0.0800 - acc: 0.9744 - val_loss: 0.0408 - val_acc: 0.9876\n",
      "Epoch 57/250\n",
      " - 7s - loss: 0.0832 - acc: 0.9740 - val_loss: 0.0345 - val_acc: 0.9892\n",
      "Epoch 58/250\n",
      " - 7s - loss: 0.0797 - acc: 0.9749 - val_loss: 0.0429 - val_acc: 0.9862\n",
      "Epoch 59/250\n",
      " - 7s - loss: 0.0782 - acc: 0.9742 - val_loss: 0.0399 - val_acc: 0.9860\n",
      "Epoch 60/250\n",
      " - 7s - loss: 0.0793 - acc: 0.9748 - val_loss: 0.0351 - val_acc: 0.9887\n",
      "Epoch 61/250\n",
      " - 7s - loss: 0.0763 - acc: 0.9754 - val_loss: 0.0398 - val_acc: 0.9883\n",
      "Epoch 62/250\n",
      " - 7s - loss: 0.0767 - acc: 0.9759 - val_loss: 0.0347 - val_acc: 0.9895\n",
      "Epoch 63/250\n",
      " - 7s - loss: 0.0777 - acc: 0.9756 - val_loss: 0.0369 - val_acc: 0.9890\n",
      "Epoch 64/250\n",
      " - 7s - loss: 0.0770 - acc: 0.9745 - val_loss: 0.0330 - val_acc: 0.9892\n",
      "Epoch 65/250\n",
      " - 7s - loss: 0.0762 - acc: 0.9759 - val_loss: 0.0368 - val_acc: 0.9887\n",
      "Epoch 66/250\n",
      " - 7s - loss: 0.0787 - acc: 0.9749 - val_loss: 0.0342 - val_acc: 0.9895\n",
      "Epoch 67/250\n",
      " - 7s - loss: 0.0797 - acc: 0.9746 - val_loss: 0.0395 - val_acc: 0.9878\n",
      "Epoch 68/250\n",
      " - 7s - loss: 0.0783 - acc: 0.9745 - val_loss: 0.0358 - val_acc: 0.9879\n",
      "Epoch 69/250\n",
      " - 7s - loss: 0.0782 - acc: 0.9754 - val_loss: 0.0457 - val_acc: 0.9865\n",
      "Epoch 70/250\n",
      " - 7s - loss: 0.0769 - acc: 0.9754 - val_loss: 0.0357 - val_acc: 0.9897\n",
      "Epoch 71/250\n",
      " - 7s - loss: 0.0736 - acc: 0.9767 - val_loss: 0.0376 - val_acc: 0.9884\n",
      "Epoch 72/250\n",
      " - 7s - loss: 0.0733 - acc: 0.9765 - val_loss: 0.0412 - val_acc: 0.9868\n",
      "Epoch 73/250\n",
      " - 7s - loss: 0.0747 - acc: 0.9761 - val_loss: 0.0387 - val_acc: 0.9884\n",
      "Epoch 74/250\n",
      " - 7s - loss: 0.0798 - acc: 0.9743 - val_loss: 0.0432 - val_acc: 0.9871\n",
      "Epoch 75/250\n",
      " - 7s - loss: 0.0739 - acc: 0.9760 - val_loss: 0.0341 - val_acc: 0.9898\n",
      "Epoch 76/250\n",
      " - 7s - loss: 0.0782 - acc: 0.9756 - val_loss: 0.0380 - val_acc: 0.9884\n",
      "Epoch 77/250\n",
      " - 7s - loss: 0.0743 - acc: 0.9761 - val_loss: 0.0397 - val_acc: 0.9868\n",
      "Epoch 78/250\n",
      " - 7s - loss: 0.0735 - acc: 0.9762 - val_loss: 0.0298 - val_acc: 0.9905\n",
      "Epoch 79/250\n",
      " - 7s - loss: 0.0757 - acc: 0.9759 - val_loss: 0.0306 - val_acc: 0.9908\n",
      "Epoch 80/250\n",
      " - 7s - loss: 0.0701 - acc: 0.9777 - val_loss: 0.0359 - val_acc: 0.9884\n",
      "Epoch 81/250\n",
      " - 7s - loss: 0.0701 - acc: 0.9776 - val_loss: 0.0344 - val_acc: 0.9887\n",
      "Epoch 82/250\n",
      " - 7s - loss: 0.0711 - acc: 0.9766 - val_loss: 0.0355 - val_acc: 0.9886\n",
      "Epoch 83/250\n",
      " - 7s - loss: 0.0707 - acc: 0.9776 - val_loss: 0.0345 - val_acc: 0.9895\n",
      "Epoch 84/250\n",
      " - 7s - loss: 0.0726 - acc: 0.9774 - val_loss: 0.0373 - val_acc: 0.9884\n",
      "Epoch 85/250\n",
      " - 7s - loss: 0.0736 - acc: 0.9762 - val_loss: 0.0363 - val_acc: 0.9895\n",
      "Epoch 86/250\n",
      " - 7s - loss: 0.0720 - acc: 0.9767 - val_loss: 0.0325 - val_acc: 0.9894\n",
      "Epoch 87/250\n",
      " - 8s - loss: 0.0733 - acc: 0.9769 - val_loss: 0.0408 - val_acc: 0.9875\n",
      "Epoch 88/250\n",
      " - 7s - loss: 0.0714 - acc: 0.9767 - val_loss: 0.0368 - val_acc: 0.9898\n",
      "Epoch 89/250\n",
      " - 7s - loss: 0.0698 - acc: 0.9773 - val_loss: 0.0344 - val_acc: 0.9889\n",
      "Epoch 90/250\n",
      " - 7s - loss: 0.0688 - acc: 0.9781 - val_loss: 0.0313 - val_acc: 0.9905\n",
      "Epoch 91/250\n",
      " - 7s - loss: 0.0712 - acc: 0.9763 - val_loss: 0.0365 - val_acc: 0.9879\n",
      "Epoch 92/250\n",
      " - 7s - loss: 0.0699 - acc: 0.9778 - val_loss: 0.0365 - val_acc: 0.9886\n",
      "Epoch 93/250\n",
      " - 7s - loss: 0.0675 - acc: 0.9782 - val_loss: 0.0379 - val_acc: 0.9878\n",
      "Epoch 94/250\n",
      " - 7s - loss: 0.0734 - acc: 0.9769 - val_loss: 0.0385 - val_acc: 0.9879\n",
      "Epoch 95/250\n",
      " - 7s - loss: 0.0708 - acc: 0.9779 - val_loss: 0.0360 - val_acc: 0.9881\n",
      "Epoch 96/250\n",
      " - 7s - loss: 0.0668 - acc: 0.9778 - val_loss: 0.0472 - val_acc: 0.9849\n",
      "Epoch 97/250\n",
      " - 7s - loss: 0.0716 - acc: 0.9766 - val_loss: 0.0397 - val_acc: 0.9884\n",
      "Epoch 98/250\n",
      " - 7s - loss: 0.0703 - acc: 0.9771 - val_loss: 0.0335 - val_acc: 0.9894\n",
      "Epoch 99/250\n",
      " - 7s - loss: 0.0701 - acc: 0.9768 - val_loss: 0.0407 - val_acc: 0.9873\n",
      "Epoch 100/250\n",
      " - 7s - loss: 0.0685 - acc: 0.9780 - val_loss: 0.0294 - val_acc: 0.9905\n",
      "Epoch 101/250\n",
      " - 7s - loss: 0.0674 - acc: 0.9780 - val_loss: 0.0411 - val_acc: 0.9870\n",
      "Epoch 102/250\n",
      " - 7s - loss: 0.0698 - acc: 0.9772 - val_loss: 0.0271 - val_acc: 0.9911\n",
      "Epoch 103/250\n",
      " - 7s - loss: 0.0696 - acc: 0.9776 - val_loss: 0.0359 - val_acc: 0.9894\n",
      "Epoch 104/250\n",
      " - 7s - loss: 0.0683 - acc: 0.9779 - val_loss: 0.0391 - val_acc: 0.9887\n",
      "Epoch 105/250\n",
      " - 7s - loss: 0.0679 - acc: 0.9783 - val_loss: 0.0344 - val_acc: 0.9898\n",
      "Epoch 106/250\n",
      " - 7s - loss: 0.0671 - acc: 0.9787 - val_loss: 0.0340 - val_acc: 0.9898\n",
      "Epoch 107/250\n",
      " - 7s - loss: 0.0686 - acc: 0.9780 - val_loss: 0.0347 - val_acc: 0.9894\n",
      "Epoch 108/250\n",
      " - 7s - loss: 0.0679 - acc: 0.9784 - val_loss: 0.0312 - val_acc: 0.9897\n",
      "Epoch 109/250\n",
      " - 7s - loss: 0.0662 - acc: 0.9778 - val_loss: 0.0344 - val_acc: 0.9902\n",
      "Epoch 110/250\n",
      " - 7s - loss: 0.0686 - acc: 0.9783 - val_loss: 0.0351 - val_acc: 0.9884\n",
      "Epoch 111/250\n",
      " - 7s - loss: 0.0667 - acc: 0.9787 - val_loss: 0.0305 - val_acc: 0.9895\n",
      "Epoch 112/250\n",
      " - 7s - loss: 0.0691 - acc: 0.9783 - val_loss: 0.0319 - val_acc: 0.9910\n",
      "Epoch 113/250\n",
      " - 7s - loss: 0.0695 - acc: 0.9776 - val_loss: 0.0339 - val_acc: 0.9903\n",
      "Epoch 114/250\n",
      " - 7s - loss: 0.0680 - acc: 0.9788 - val_loss: 0.0300 - val_acc: 0.9894\n",
      "Epoch 115/250\n",
      " - 7s - loss: 0.0651 - acc: 0.9791 - val_loss: 0.0379 - val_acc: 0.9865\n",
      "Epoch 116/250\n",
      " - 7s - loss: 0.0662 - acc: 0.9797 - val_loss: 0.0376 - val_acc: 0.9879\n",
      "Epoch 117/250\n",
      " - 7s - loss: 0.0690 - acc: 0.9766 - val_loss: 0.0324 - val_acc: 0.9895\n",
      "Epoch 118/250\n",
      " - 7s - loss: 0.0700 - acc: 0.9778 - val_loss: 0.0336 - val_acc: 0.9881\n",
      "Epoch 119/250\n",
      " - 7s - loss: 0.0646 - acc: 0.9797 - val_loss: 0.0312 - val_acc: 0.9903\n",
      "Epoch 120/250\n",
      " - 7s - loss: 0.0696 - acc: 0.9772 - val_loss: 0.0348 - val_acc: 0.9884\n",
      "Epoch 121/250\n",
      " - 7s - loss: 0.0644 - acc: 0.9799 - val_loss: 0.0320 - val_acc: 0.9895\n",
      "Epoch 122/250\n",
      " - 7s - loss: 0.0645 - acc: 0.9788 - val_loss: 0.0323 - val_acc: 0.9895\n",
      "Epoch 123/250\n",
      " - 7s - loss: 0.0675 - acc: 0.9790 - val_loss: 0.0347 - val_acc: 0.9889\n",
      "Epoch 124/250\n",
      " - 7s - loss: 0.0672 - acc: 0.9785 - val_loss: 0.0336 - val_acc: 0.9889\n",
      "Epoch 125/250\n",
      " - 7s - loss: 0.0623 - acc: 0.9804 - val_loss: 0.0477 - val_acc: 0.9851\n",
      "Epoch 126/250\n",
      " - 7s - loss: 0.0647 - acc: 0.9791 - val_loss: 0.0355 - val_acc: 0.9884\n",
      "Epoch 127/250\n",
      " - 7s - loss: 0.0662 - acc: 0.9790 - val_loss: 0.0327 - val_acc: 0.9889\n",
      "Epoch 128/250\n",
      " - 7s - loss: 0.0664 - acc: 0.9789 - val_loss: 0.0360 - val_acc: 0.9887\n",
      "Epoch 129/250\n",
      " - 8s - loss: 0.0678 - acc: 0.9787 - val_loss: 0.0346 - val_acc: 0.9894\n",
      "Epoch 130/250\n",
      " - 7s - loss: 0.0663 - acc: 0.9788 - val_loss: 0.0377 - val_acc: 0.9887\n",
      "Epoch 131/250\n",
      " - 7s - loss: 0.0662 - acc: 0.9787 - val_loss: 0.0310 - val_acc: 0.9902\n",
      "Epoch 132/250\n",
      " - 7s - loss: 0.0662 - acc: 0.9784 - val_loss: 0.0361 - val_acc: 0.9881\n",
      "Epoch 133/250\n",
      " - 7s - loss: 0.0663 - acc: 0.9785 - val_loss: 0.0342 - val_acc: 0.9883\n",
      "Epoch 134/250\n",
      " - 7s - loss: 0.0629 - acc: 0.9794 - val_loss: 0.0365 - val_acc: 0.9892\n",
      "Epoch 135/250\n",
      " - 7s - loss: 0.0657 - acc: 0.9787 - val_loss: 0.0303 - val_acc: 0.9906\n",
      "Epoch 136/250\n",
      " - 7s - loss: 0.0635 - acc: 0.9795 - val_loss: 0.0327 - val_acc: 0.9898\n",
      "Epoch 137/250\n",
      " - 7s - loss: 0.0644 - acc: 0.9792 - val_loss: 0.0332 - val_acc: 0.9890\n",
      "Epoch 138/250\n",
      " - 7s - loss: 0.0626 - acc: 0.9795 - val_loss: 0.0322 - val_acc: 0.9892\n",
      "Epoch 139/250\n",
      " - 7s - loss: 0.0640 - acc: 0.9796 - val_loss: 0.0365 - val_acc: 0.9878\n",
      "Epoch 140/250\n",
      " - 7s - loss: 0.0659 - acc: 0.9789 - val_loss: 0.0338 - val_acc: 0.9883\n",
      "Epoch 141/250\n",
      " - 7s - loss: 0.0693 - acc: 0.9777 - val_loss: 0.0297 - val_acc: 0.9897\n",
      "Epoch 142/250\n",
      " - 7s - loss: 0.0611 - acc: 0.9799 - val_loss: 0.0359 - val_acc: 0.9878\n",
      "Epoch 143/250\n",
      " - 7s - loss: 0.0639 - acc: 0.9791 - val_loss: 0.0339 - val_acc: 0.9892\n",
      "Epoch 144/250\n",
      " - 7s - loss: 0.0636 - acc: 0.9797 - val_loss: 0.0307 - val_acc: 0.9902\n",
      "Epoch 145/250\n",
      " - 7s - loss: 0.0623 - acc: 0.9797 - val_loss: 0.0321 - val_acc: 0.9902\n",
      "Epoch 146/250\n",
      " - 7s - loss: 0.0629 - acc: 0.9790 - val_loss: 0.0337 - val_acc: 0.9887\n",
      "Epoch 147/250\n",
      " - 7s - loss: 0.0619 - acc: 0.9797 - val_loss: 0.0333 - val_acc: 0.9900\n",
      "Epoch 148/250\n",
      " - 7s - loss: 0.0617 - acc: 0.9802 - val_loss: 0.0316 - val_acc: 0.9905\n",
      "Epoch 149/250\n",
      " - 7s - loss: 0.0605 - acc: 0.9810 - val_loss: 0.0375 - val_acc: 0.9884\n",
      "Epoch 150/250\n",
      " - 7s - loss: 0.0647 - acc: 0.9785 - val_loss: 0.0319 - val_acc: 0.9902\n",
      "Epoch 151/250\n",
      " - 7s - loss: 0.0611 - acc: 0.9800 - val_loss: 0.0342 - val_acc: 0.9889\n",
      "Epoch 152/250\n",
      " - 7s - loss: 0.0645 - acc: 0.9797 - val_loss: 0.0348 - val_acc: 0.9890\n",
      "Epoch 153/250\n",
      " - 7s - loss: 0.0605 - acc: 0.9803 - val_loss: 0.0359 - val_acc: 0.9887\n",
      "Epoch 154/250\n",
      " - 7s - loss: 0.0599 - acc: 0.9805 - val_loss: 0.0385 - val_acc: 0.9878\n",
      "Epoch 155/250\n",
      " - 7s - loss: 0.0621 - acc: 0.9796 - val_loss: 0.0334 - val_acc: 0.9903\n",
      "Epoch 156/250\n",
      " - 7s - loss: 0.0649 - acc: 0.9789 - val_loss: 0.0360 - val_acc: 0.9883\n",
      "Epoch 157/250\n",
      " - 7s - loss: 0.0636 - acc: 0.9800 - val_loss: 0.0319 - val_acc: 0.9898\n",
      "Epoch 158/250\n",
      " - 7s - loss: 0.0651 - acc: 0.9796 - val_loss: 0.0371 - val_acc: 0.9868\n",
      "Epoch 159/250\n",
      " - 7s - loss: 0.0645 - acc: 0.9789 - val_loss: 0.0329 - val_acc: 0.9897\n",
      "Epoch 160/250\n",
      " - 7s - loss: 0.0601 - acc: 0.9802 - val_loss: 0.0397 - val_acc: 0.9871\n",
      "Epoch 161/250\n",
      " - 7s - loss: 0.0587 - acc: 0.9807 - val_loss: 0.0392 - val_acc: 0.9894\n",
      "Epoch 162/250\n",
      " - 7s - loss: 0.0632 - acc: 0.9787 - val_loss: 0.0325 - val_acc: 0.9890\n",
      "Epoch 163/250\n",
      " - 7s - loss: 0.0619 - acc: 0.9796 - val_loss: 0.0332 - val_acc: 0.9895\n",
      "Epoch 164/250\n",
      " - 7s - loss: 0.0592 - acc: 0.9804 - val_loss: 0.0291 - val_acc: 0.9914\n",
      "Epoch 165/250\n",
      " - 7s - loss: 0.0620 - acc: 0.9805 - val_loss: 0.0368 - val_acc: 0.9897\n",
      "Epoch 166/250\n",
      " - 7s - loss: 0.0601 - acc: 0.9800 - val_loss: 0.0369 - val_acc: 0.9884\n",
      "Epoch 167/250\n",
      " - 7s - loss: 0.0607 - acc: 0.9801 - val_loss: 0.0296 - val_acc: 0.9897\n",
      "Epoch 168/250\n",
      " - 7s - loss: 0.0633 - acc: 0.9794 - val_loss: 0.0300 - val_acc: 0.9906\n",
      "Epoch 169/250\n",
      " - 7s - loss: 0.0594 - acc: 0.9805 - val_loss: 0.0330 - val_acc: 0.9892\n",
      "Epoch 170/250\n",
      " - 7s - loss: 0.0618 - acc: 0.9796 - val_loss: 0.0339 - val_acc: 0.9902\n",
      "Epoch 171/250\n",
      " - 7s - loss: 0.0585 - acc: 0.9804 - val_loss: 0.0291 - val_acc: 0.9913\n",
      "Epoch 172/250\n",
      " - 8s - loss: 0.0616 - acc: 0.9798 - val_loss: 0.0340 - val_acc: 0.9892\n",
      "Epoch 173/250\n",
      " - 7s - loss: 0.0615 - acc: 0.9794 - val_loss: 0.0342 - val_acc: 0.9886\n",
      "Epoch 174/250\n",
      " - 7s - loss: 0.0592 - acc: 0.9807 - val_loss: 0.0327 - val_acc: 0.9908\n",
      "Epoch 175/250\n",
      " - 7s - loss: 0.0617 - acc: 0.9804 - val_loss: 0.0301 - val_acc: 0.9902\n",
      "Epoch 176/250\n",
      " - 7s - loss: 0.0600 - acc: 0.9813 - val_loss: 0.0328 - val_acc: 0.9886\n",
      "Epoch 177/250\n",
      " - 7s - loss: 0.0578 - acc: 0.9816 - val_loss: 0.0287 - val_acc: 0.9895\n",
      "Epoch 178/250\n",
      " - 7s - loss: 0.0612 - acc: 0.9800 - val_loss: 0.0296 - val_acc: 0.9910\n",
      "Epoch 179/250\n",
      " - 7s - loss: 0.0595 - acc: 0.9805 - val_loss: 0.0273 - val_acc: 0.9900\n",
      "Epoch 180/250\n",
      " - 7s - loss: 0.0615 - acc: 0.9800 - val_loss: 0.0266 - val_acc: 0.9898\n",
      "Epoch 181/250\n",
      " - 7s - loss: 0.0576 - acc: 0.9815 - val_loss: 0.0290 - val_acc: 0.9903\n",
      "Epoch 182/250\n",
      " - 7s - loss: 0.0624 - acc: 0.9805 - val_loss: 0.0300 - val_acc: 0.9902\n",
      "Epoch 183/250\n",
      " - 7s - loss: 0.0606 - acc: 0.9806 - val_loss: 0.0388 - val_acc: 0.9886\n",
      "Epoch 184/250\n",
      " - 7s - loss: 0.0601 - acc: 0.9811 - val_loss: 0.0338 - val_acc: 0.9897\n",
      "Epoch 185/250\n",
      " - 7s - loss: 0.0609 - acc: 0.9805 - val_loss: 0.0310 - val_acc: 0.9903\n",
      "Epoch 186/250\n",
      " - 7s - loss: 0.0594 - acc: 0.9806 - val_loss: 0.0378 - val_acc: 0.9881\n",
      "Epoch 187/250\n",
      " - 7s - loss: 0.0581 - acc: 0.9814 - val_loss: 0.0304 - val_acc: 0.9905\n",
      "Epoch 188/250\n",
      " - 7s - loss: 0.0573 - acc: 0.9813 - val_loss: 0.0344 - val_acc: 0.9892\n",
      "Epoch 189/250\n",
      " - 7s - loss: 0.0578 - acc: 0.9810 - val_loss: 0.0301 - val_acc: 0.9905\n",
      "Epoch 190/250\n",
      " - 7s - loss: 0.0595 - acc: 0.9807 - val_loss: 0.0321 - val_acc: 0.9898\n",
      "Epoch 191/250\n",
      " - 7s - loss: 0.0565 - acc: 0.9813 - val_loss: 0.0324 - val_acc: 0.9900\n",
      "Epoch 192/250\n",
      " - 7s - loss: 0.0600 - acc: 0.9806 - val_loss: 0.0297 - val_acc: 0.9910\n",
      "Epoch 193/250\n",
      " - 7s - loss: 0.0572 - acc: 0.9819 - val_loss: 0.0270 - val_acc: 0.9919\n",
      "Epoch 194/250\n",
      " - 7s - loss: 0.0585 - acc: 0.9813 - val_loss: 0.0491 - val_acc: 0.9846\n",
      "Epoch 195/250\n",
      " - 7s - loss: 0.0603 - acc: 0.9804 - val_loss: 0.0338 - val_acc: 0.9890\n",
      "Epoch 196/250\n",
      " - 7s - loss: 0.0572 - acc: 0.9816 - val_loss: 0.0341 - val_acc: 0.9884\n",
      "Epoch 197/250\n",
      " - 7s - loss: 0.0591 - acc: 0.9809 - val_loss: 0.0357 - val_acc: 0.9895\n",
      "Epoch 198/250\n",
      " - 7s - loss: 0.0588 - acc: 0.9811 - val_loss: 0.0283 - val_acc: 0.9905\n",
      "Epoch 199/250\n",
      " - 7s - loss: 0.0586 - acc: 0.9811 - val_loss: 0.0329 - val_acc: 0.9892\n",
      "Epoch 200/250\n",
      " - 7s - loss: 0.0589 - acc: 0.9810 - val_loss: 0.0389 - val_acc: 0.9883\n",
      "Epoch 201/250\n",
      " - 7s - loss: 0.0600 - acc: 0.9805 - val_loss: 0.0323 - val_acc: 0.9898\n",
      "Epoch 202/250\n",
      " - 7s - loss: 0.0566 - acc: 0.9810 - val_loss: 0.0370 - val_acc: 0.9890\n",
      "Epoch 203/250\n",
      " - 7s - loss: 0.0597 - acc: 0.9806 - val_loss: 0.0330 - val_acc: 0.9897\n",
      "Epoch 204/250\n",
      " - 7s - loss: 0.0584 - acc: 0.9819 - val_loss: 0.0263 - val_acc: 0.9910\n",
      "Epoch 205/250\n",
      " - 7s - loss: 0.0586 - acc: 0.9804 - val_loss: 0.0351 - val_acc: 0.9889\n",
      "Epoch 206/250\n",
      " - 7s - loss: 0.0589 - acc: 0.9803 - val_loss: 0.0282 - val_acc: 0.9903\n",
      "Epoch 207/250\n",
      " - 7s - loss: 0.0564 - acc: 0.9826 - val_loss: 0.0279 - val_acc: 0.9924\n",
      "Epoch 208/250\n",
      " - 7s - loss: 0.0579 - acc: 0.9812 - val_loss: 0.0368 - val_acc: 0.9878\n",
      "Epoch 209/250\n",
      " - 7s - loss: 0.0549 - acc: 0.9827 - val_loss: 0.0358 - val_acc: 0.9892\n",
      "Epoch 210/250\n",
      " - 7s - loss: 0.0583 - acc: 0.9806 - val_loss: 0.0311 - val_acc: 0.9895\n",
      "Epoch 211/250\n",
      " - 7s - loss: 0.0584 - acc: 0.9812 - val_loss: 0.0322 - val_acc: 0.9892\n",
      "Epoch 212/250\n",
      " - 7s - loss: 0.0587 - acc: 0.9806 - val_loss: 0.0330 - val_acc: 0.9894\n",
      "Epoch 213/250\n",
      " - 7s - loss: 0.0606 - acc: 0.9807 - val_loss: 0.0310 - val_acc: 0.9898\n",
      "Epoch 214/250\n",
      " - 7s - loss: 0.0547 - acc: 0.9829 - val_loss: 0.0315 - val_acc: 0.9906\n",
      "Epoch 215/250\n",
      " - 8s - loss: 0.0568 - acc: 0.9821 - val_loss: 0.0339 - val_acc: 0.9894\n",
      "Epoch 216/250\n",
      " - 7s - loss: 0.0580 - acc: 0.9809 - val_loss: 0.0297 - val_acc: 0.9914\n",
      "Epoch 217/250\n",
      " - 7s - loss: 0.0592 - acc: 0.9804 - val_loss: 0.0293 - val_acc: 0.9902\n",
      "Epoch 218/250\n",
      " - 7s - loss: 0.0585 - acc: 0.9807 - val_loss: 0.0300 - val_acc: 0.9897\n",
      "Epoch 219/250\n",
      " - 7s - loss: 0.0586 - acc: 0.9803 - val_loss: 0.0360 - val_acc: 0.9884\n",
      "Epoch 220/250\n",
      " - 7s - loss: 0.0572 - acc: 0.9815 - val_loss: 0.0280 - val_acc: 0.9906\n",
      "Epoch 221/250\n",
      " - 7s - loss: 0.0579 - acc: 0.9806 - val_loss: 0.0292 - val_acc: 0.9914\n",
      "Epoch 222/250\n",
      " - 7s - loss: 0.0568 - acc: 0.9813 - val_loss: 0.0378 - val_acc: 0.9886\n",
      "Epoch 223/250\n",
      " - 7s - loss: 0.0578 - acc: 0.9809 - val_loss: 0.0356 - val_acc: 0.9894\n",
      "Epoch 224/250\n",
      " - 7s - loss: 0.0574 - acc: 0.9808 - val_loss: 0.0302 - val_acc: 0.9903\n",
      "Epoch 225/250\n",
      " - 7s - loss: 0.0529 - acc: 0.9829 - val_loss: 0.0373 - val_acc: 0.9887\n",
      "Epoch 226/250\n",
      " - 7s - loss: 0.0568 - acc: 0.9816 - val_loss: 0.0296 - val_acc: 0.9905\n",
      "Epoch 227/250\n",
      " - 7s - loss: 0.0584 - acc: 0.9815 - val_loss: 0.0324 - val_acc: 0.9900\n",
      "Epoch 228/250\n",
      " - 7s - loss: 0.0565 - acc: 0.9822 - val_loss: 0.0293 - val_acc: 0.9914\n",
      "Epoch 229/250\n",
      " - 7s - loss: 0.0541 - acc: 0.9824 - val_loss: 0.0342 - val_acc: 0.9890\n",
      "Epoch 230/250\n",
      " - 7s - loss: 0.0577 - acc: 0.9814 - val_loss: 0.0352 - val_acc: 0.9895\n",
      "Epoch 231/250\n",
      " - 7s - loss: 0.0561 - acc: 0.9824 - val_loss: 0.0344 - val_acc: 0.9898\n",
      "Epoch 232/250\n",
      " - 7s - loss: 0.0566 - acc: 0.9815 - val_loss: 0.0336 - val_acc: 0.9897\n",
      "Epoch 233/250\n",
      " - 7s - loss: 0.0559 - acc: 0.9822 - val_loss: 0.0333 - val_acc: 0.9897\n",
      "Epoch 234/250\n",
      " - 7s - loss: 0.0585 - acc: 0.9817 - val_loss: 0.0369 - val_acc: 0.9875\n",
      "Epoch 235/250\n",
      " - 7s - loss: 0.0568 - acc: 0.9817 - val_loss: 0.0287 - val_acc: 0.9919\n",
      "Epoch 236/250\n",
      " - 7s - loss: 0.0537 - acc: 0.9831 - val_loss: 0.0327 - val_acc: 0.9916\n",
      "Epoch 237/250\n",
      " - 7s - loss: 0.0586 - acc: 0.9813 - val_loss: 0.0306 - val_acc: 0.9908\n",
      "Epoch 238/250\n",
      " - 7s - loss: 0.0548 - acc: 0.9824 - val_loss: 0.0335 - val_acc: 0.9900\n",
      "Epoch 239/250\n",
      " - 7s - loss: 0.0572 - acc: 0.9819 - val_loss: 0.0277 - val_acc: 0.9914\n",
      "Epoch 240/250\n",
      " - 7s - loss: 0.0537 - acc: 0.9824 - val_loss: 0.0367 - val_acc: 0.9886\n",
      "Epoch 241/250\n",
      " - 7s - loss: 0.0585 - acc: 0.9808 - val_loss: 0.0303 - val_acc: 0.9908\n",
      "Epoch 242/250\n",
      " - 7s - loss: 0.0564 - acc: 0.9816 - val_loss: 0.0309 - val_acc: 0.9911\n",
      "Epoch 243/250\n",
      " - 7s - loss: 0.0532 - acc: 0.9832 - val_loss: 0.0338 - val_acc: 0.9887\n",
      "Epoch 244/250\n",
      " - 7s - loss: 0.0558 - acc: 0.9816 - val_loss: 0.0314 - val_acc: 0.9900\n",
      "Epoch 245/250\n",
      " - 7s - loss: 0.0563 - acc: 0.9816 - val_loss: 0.0323 - val_acc: 0.9900\n",
      "Epoch 246/250\n",
      " - 7s - loss: 0.0557 - acc: 0.9816 - val_loss: 0.0318 - val_acc: 0.9894\n",
      "Epoch 247/250\n",
      " - 7s - loss: 0.0555 - acc: 0.9821 - val_loss: 0.0284 - val_acc: 0.9906\n",
      "Epoch 248/250\n",
      " - 7s - loss: 0.0539 - acc: 0.9816 - val_loss: 0.0292 - val_acc: 0.9911\n",
      "Epoch 249/250\n",
      " - 7s - loss: 0.0537 - acc: 0.9822 - val_loss: 0.0286 - val_acc: 0.9916\n",
      "Epoch 250/250\n",
      " - 7s - loss: 0.0557 - acc: 0.9817 - val_loss: 0.0326 - val_acc: 0.9898\n"
     ]
    }
   ],
   "source": [
    "checkpoint =model.fit_generator(datagen.flow(X_train,y_train,batch_size=batch_size),epochs=epochs,validation_data= (X_valid,y_valid),verbose=2,steps_per_epoch=X_train.shape[0]/batch_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300/6300 [==============================] - 0s 68us/step\n",
      "\n",
      " Test accuracy: 98.98\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_valid,y_valid,verbose=1)\n",
    "print('\\n', 'Test accuracy:', round(score[1]*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"mysubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
